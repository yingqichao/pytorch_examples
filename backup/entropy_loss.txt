lambda = 0.01:(适中)
Curr entropy: 6.802065749746229
Train Epoch: 14 [50560/60000 (84%)]	Loss: 0.089251 which contains 76.21% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [51200/60000 (85%)]	Loss: 0.103279 which contains 65.86% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [51840/60000 (86%)]	Loss: 0.075437 which contains 90.17% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [52480/60000 (87%)]	Loss: 0.071768 which contains 94.78% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [53120/60000 (88%)]	Loss: 0.080117 which contains 84.90% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [53760/60000 (90%)]	Loss: 0.148286 which contains 45.87% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [54400/60000 (91%)]	Loss: 0.137627 which contains 49.42% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [55040/60000 (92%)]	Loss: 0.080137 which contains 84.88% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [55680/60000 (93%)]	Loss: 0.090213 which contains 75.41% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [56320/60000 (94%)]	Loss: 0.083862 which contains 81.11% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [56960/60000 (95%)]	Loss: 0.079204 which contains 85.88% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [57600/60000 (96%)]	Loss: 0.125913 which contains 54.02% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [58240/60000 (97%)]	Loss: 0.075102 which contains 90.57% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [58880/60000 (98%)]	Loss: 0.071109 which contains 95.66% Entropy Loss (Entropy: 6.80)
Train Epoch: 14 [59520/60000 (99%)]	Loss: 0.071624 which contains 94.97% Entropy Loss (Entropy: 6.80)
Test set: Average loss: 0.0272, Accuracy: 9909/10000 (99%)

lambda = 0.1  (太大)
Train Epoch: 14 [53760/60000 (90%)]	Loss: 0.760490 which contains 89.45% Entropy Loss (Entropy: 6.8023)
